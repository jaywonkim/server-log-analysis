# server-log-analysis
Analysis of logs generated by web servers using machine learning.
The code isn't very clean. Help in cleaning up the code would be appreciated. I did this project to better understand machine/ deep learning as well as data cleaning and collection.

### Dependencies:
* Python3.5
* numpy
* keras
* sklearn
* matplotlib
* PyQt4
* Pandas
* TensorFlow

Three different design approaches have been analysed.

## 1.0 General Traffic Analysis
General traffic analysis can help monitor the server usage using the web logs. Different statistics can
be gleaned from the logs such as the fraction of users on a particular day, ratio of successful to
unsuccessful requests, frequency by which the server was accessed etc. This was implemented using pandas, matplotlib, numpy.


## 2.0 Intrusion Detection
Intrusion detection is the identification of cyber-attacks on a web server. This involves identifying
different features that can be used to classify an such as ​ url length ​ , ​ http reply code, strings in the url
etc.
The features are identified by a cyber-security expert and malicious logs marked as such by them. For
the purposes of this experiment, the malicious logs were created and inserted into the server-logs
dataset. The logs were then marked accordingly as being malicious(=1) or benign(=0). Classifiers are
then trained on this dataset. The trained model is then used to predict on a test dataset and the
accuracy is calculated.
Three different classifiers were used for this namely Decision trees, logistic regression, and Artificial Neural Networks.


## 3.0 Time Series Forecasting
Time series forecasting is used to predict the future data based on the previous data. Once a baseline
prediction has been made, the future data can be identified as being anomalous depending on its
distance from the predicted value. Forecasting can also be used to predict trends. For example, if the
number of users increase at a particular time of day, appropriate measures can be taken so that server
doesn’t crash.
RNN-LSTM was used for this.


# Results

## 1.0 General Analysis:
### 1.1 Percentage Of Reply Codes
This shows the percentage of successful, failed and redirect requests made to the server.
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/pie.png)

### 1.2 Size Of Contents Returned By The Server Across The Day
This plot shows the size of data response by the server(data requested by the user) across a sample of
the data set.![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/line.png)

### 1.3 Frequency At which A particular User Accessed The Sent A Request
Anomalous users can be detected using this. Anomaly lies far away from the majority data.
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/bar_users.png)

### 1.4 Frequency At Which Each Target URL Was Accessed
Each URL was cat-coded into integers and then plotted.
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/url-bar.png)


## 2.0 Intruder Detection:
### 2.1 Decision Trees:
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/decision-trees.png)


### 2.2 Logistic Regression:
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/logistic-regression.png)


### 2.3 Artificial Neural Network:
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/ann.png)





## 3.0 Time Series Forecasting:

Univariate forecasting has been done. Multivariate forecasting is still incomplete.

### Data set
From the cleaned server logs, two columns- Timestamp and Reply size are extracted. The data is
divided into training set and test set.

![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/uni-forecasting-data.png)

The accuracy of the rnn model depends on the amount of data as well as on the hyper parameters
such as ​ batch-size ​ , ​ number of epochs ​ , and ​ number of neurons ​ . To identify the optimum parameters to
train the model, a few experiments were run and results plotted.

![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/actual-series.png)

_A line plot of a part of the data. This figure shows the sum of all values of REPLY_SIZE on a single day
from 12-Dec-2015 to 9-Jan-2016. This is the total data that the server has responded upon request._

### Model Evaluation:
* Each time step of the test dataset will be walked one at a time.
* This mimics a real-world scenario where new server-logs would be available.
This will be simulated by the structure of the train and test datasets.
* All forecasts on the test dataset will be collected and an error score calculated to summarize the
skill of the model. The root mean squared error (RMSE) will be used as it punishes large errors
and results in a score that is in the same units as the forecast data, namely daily
REPLY_SIZE(in bytes).

### Data Preparation:
* Transform the time series data so that it is stationary. Specifically, a lag=1 differencing to
remove the increasing trend in the data.
* Transform the time series into a supervised learning problem. Specifically, the organization of
data into input and output patterns where the observation at the previous time step is used as
an input to forecast the observation at the current time time step
* Transform the observations to have a specific scale. Specifically, to rescale the data to values
between -1 and 1 to meet the default hyperbolic tangent activation function of the LSTM model.
These transforms are inverted on forecasts to return them into their original scale before calculating
and error score.


### Hyperparameter Tuning: 
#### Number of Epochs
The batch size was set to 4 and different number of epochs were tried to find the one that gives the
best results.
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/epoch(batch4)screenshot.png)
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/epoch(batch4).png)

* The mean gives an idea of the average expected performance of a configuration, whereas the standard
deviation gives an idea of the variance.
* The min and max RMSE scores also give an idea of the range of possible best and worst case
examples that might be expected.
* Looking at just the mean RMSE scores, the results suggest that an epoch configured to 1000 may be
better.


#### Batch Size
Batch sizes 1, 2 and 4 were tried and results are as shown below.
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/batchsizecomparescreenshot.png)
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/batchsizecomparisionboxplot.png)

* The plot shows the median performance as a green line where a batch size of 4 shows both the largest
variability and also the lowest median RMSE.



#### Number Of Neurons
The number of neurons affects the learning capacity of the network. More neurons would help better the accuracy at the cost of
training time.
Batch size of 4 and 1000 training epochs will be used.  
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/numberofneuronscreenshotpart1.png)
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/numberofneuronscreenshotpart2.png)
![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/neurons.png)
  

From the mean performance alone, the results suggest a network configuration with 1 neuron as having
the best performance over 1000 epochs with a batch size of 4. This configuration also shows the
tightest variance.

#### Prediction
The size of the dataset was 3,84,966. After the model has been trained, it was tested on a new dataset.
The forecast was made on 12 new dates as shown below. In the line-plot, blue colour shows the actual
values and the orange colour shows the predicted values.

![alt text](https://github.com/scarecrow21/server-log-analysis/blob/master/graphs/actual_univariate_rnn%20graph.png)


